{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from lib.utils.config_parse import cfg_from_file\n",
    "# from lib.ssds_train import test_model\n",
    "\n",
    "from lib.dataset.dataset_factory import load_data\n",
    "from lib.utils.config_parse import cfg\n",
    "from lib.modeling.model_builder import create_model\n",
    "\n",
    "from lib.layers import Detect\n",
    "from lib.utils.timer import Timer\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "sys.path.append('/workspace/raid/data/jgusak/for_yulia/')\n",
    "\n",
    "from torchvision.models import resnet18\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ResNet18 "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "m = resnet18(pretrained = True)\n",
    "checkpoint = copy.deepcopy(m.state_dict())\n",
    "\n",
    "save_folder = '/workspace/raid/data/jgusak/ssds.pytorch/'\n",
    "torch.save(checkpoint, save_folder + 'resnet18_imagenet_ckpt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = resnet18(pretrained = True)\n",
    "checkpoint = copy.deepcopy(m.state_dict())\n",
    "\n",
    "# change the name of the weights which exists in other model\n",
    "change_dict = {\n",
    "        'conv1.weight':'base.0.weight',\n",
    "        'bn1.running_mean':'base.1.running_mean',\n",
    "        'bn1.running_var':'base.1.running_var',\n",
    "        'bn1.bias':'base.1.bias',\n",
    "        'bn1.weight':'base.1.weight',\n",
    "        }\n",
    "\n",
    "for k, v in list(checkpoint.items()):\n",
    "    for _k, _v in list(change_dict.items()):\n",
    "        if _k == k:\n",
    "            new_key = k.replace(_k, _v)\n",
    "            checkpoint[new_key] = checkpoint.pop(k)\n",
    "            \n",
    "change_dict = {'layer1.{:d}.'.format(i):'base.{:d}.'.format(i+4) for i in range(20)}\n",
    "change_dict.update({'layer2.{:d}.'.format(i):'base.{:d}.'.format(i+6) for i in range(20)})\n",
    "change_dict.update({'layer3.{:d}.'.format(i):'base.{:d}.'.format(i+8) for i in range(30)})\n",
    "\n",
    "for k, v in list(checkpoint.items()):\n",
    "    for _k, _v in list(change_dict.items()):\n",
    "        if _k in k:\n",
    "            new_key = k.replace(_k, _v)\n",
    "            checkpoint[new_key] = checkpoint.pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['bn1.num_batches_tracked', 'layer4.0.conv1.weight', 'layer4.0.bn1.weight', 'layer4.0.bn1.bias', 'layer4.0.bn1.running_mean', 'layer4.0.bn1.running_var', 'layer4.0.bn1.num_batches_tracked', 'layer4.0.conv2.weight', 'layer4.0.bn2.weight', 'layer4.0.bn2.bias', 'layer4.0.bn2.running_mean', 'layer4.0.bn2.running_var', 'layer4.0.bn2.num_batches_tracked', 'layer4.0.downsample.0.weight', 'layer4.0.downsample.1.weight', 'layer4.0.downsample.1.bias', 'layer4.0.downsample.1.running_mean', 'layer4.0.downsample.1.running_var', 'layer4.0.downsample.1.num_batches_tracked', 'layer4.1.conv1.weight', 'layer4.1.bn1.weight', 'layer4.1.bn1.bias', 'layer4.1.bn1.running_mean', 'layer4.1.bn1.running_var', 'layer4.1.bn1.num_batches_tracked', 'layer4.1.conv2.weight', 'layer4.1.bn2.weight', 'layer4.1.bn2.bias', 'layer4.1.bn2.running_mean', 'layer4.1.bn2.running_var', 'layer4.1.bn2.num_batches_tracked', 'fc.weight', 'fc.bias', 'base.0.weight', 'base.1.weight', 'base.1.bias', 'base.1.running_mean', 'base.1.running_var', 'base.4.conv1.weight', 'base.4.bn1.weight', 'base.4.bn1.bias', 'base.4.bn1.running_mean', 'base.4.bn1.running_var', 'base.4.bn1.num_batches_tracked', 'base.4.conv2.weight', 'base.4.bn2.weight', 'base.4.bn2.bias', 'base.4.bn2.running_mean', 'base.4.bn2.running_var', 'base.4.bn2.num_batches_tracked', 'base.5.conv1.weight', 'base.5.bn1.weight', 'base.5.bn1.bias', 'base.5.bn1.running_mean', 'base.5.bn1.running_var', 'base.5.bn1.num_batches_tracked', 'base.5.conv2.weight', 'base.5.bn2.weight', 'base.5.bn2.bias', 'base.5.bn2.running_mean', 'base.5.bn2.running_var', 'base.5.bn2.num_batches_tracked', 'base.6.conv1.weight', 'base.6.bn1.weight', 'base.6.bn1.bias', 'base.6.bn1.running_mean', 'base.6.bn1.running_var', 'base.6.bn1.num_batches_tracked', 'base.6.conv2.weight', 'base.6.bn2.weight', 'base.6.bn2.bias', 'base.6.bn2.running_mean', 'base.6.bn2.running_var', 'base.6.bn2.num_batches_tracked', 'base.6.downsample.0.weight', 'base.6.downsample.1.weight', 'base.6.downsample.1.bias', 'base.6.downsample.1.running_mean', 'base.6.downsample.1.running_var', 'base.6.downsample.1.num_batches_tracked', 'base.7.conv1.weight', 'base.7.bn1.weight', 'base.7.bn1.bias', 'base.7.bn1.running_mean', 'base.7.bn1.running_var', 'base.7.bn1.num_batches_tracked', 'base.7.conv2.weight', 'base.7.bn2.weight', 'base.7.bn2.bias', 'base.7.bn2.running_mean', 'base.7.bn2.running_var', 'base.7.bn2.num_batches_tracked', 'base.8.conv1.weight', 'base.8.bn1.weight', 'base.8.bn1.bias', 'base.8.bn1.running_mean', 'base.8.bn1.running_var', 'base.8.bn1.num_batches_tracked', 'base.8.conv2.weight', 'base.8.bn2.weight', 'base.8.bn2.bias', 'base.8.bn2.running_mean', 'base.8.bn2.running_var', 'base.8.bn2.num_batches_tracked', 'base.8.downsample.0.weight', 'base.8.downsample.1.weight', 'base.8.downsample.1.bias', 'base.8.downsample.1.running_mean', 'base.8.downsample.1.running_var', 'base.8.downsample.1.num_batches_tracked', 'base.9.conv1.weight', 'base.9.bn1.weight', 'base.9.bn1.bias', 'base.9.bn1.running_mean', 'base.9.bn1.running_var', 'base.9.bn1.num_batches_tracked', 'base.9.conv2.weight', 'base.9.bn2.weight', 'base.9.bn2.bias', 'base.9.bn2.running_mean', 'base.9.bn2.running_var', 'base.9.bn2.num_batches_tracked'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./experiments/cfgs/ssd_resnet18_train_voc.yml\n",
      "===> Building model\n",
      "==>Feature map size:\n",
      "[(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/home/jgusak/ssds.pytorch/lib/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n"
     ]
    }
   ],
   "source": [
    "config_file =  './experiments/cfgs/ssd_resnet18_train_voc.yml'\n",
    "cfg_from_file(config_file)\n",
    "\n",
    "print(config_file)\n",
    "\n",
    "\n",
    "# Build model\n",
    "print('===> Building model')\n",
    "model, _ = create_model(cfg.MODEL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = model.state_dict()\n",
    "pretrained_dict = {k:v for k,v in checkpoint.items() if k in model_dict.keys()}\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['base.0.weight', 'base.1.weight', 'base.1.bias', 'base.1.running_mean', 'base.1.running_var', 'base.1.num_batches_tracked', 'base.4.conv1.weight', 'base.4.bn1.weight', 'base.4.bn1.bias', 'base.4.bn1.running_mean', 'base.4.bn1.running_var', 'base.4.bn1.num_batches_tracked', 'base.4.conv2.weight', 'base.4.bn2.weight', 'base.4.bn2.bias', 'base.4.bn2.running_mean', 'base.4.bn2.running_var', 'base.4.bn2.num_batches_tracked', 'base.5.conv1.weight', 'base.5.bn1.weight', 'base.5.bn1.bias', 'base.5.bn1.running_mean', 'base.5.bn1.running_var', 'base.5.bn1.num_batches_tracked', 'base.5.conv2.weight', 'base.5.bn2.weight', 'base.5.bn2.bias', 'base.5.bn2.running_mean', 'base.5.bn2.running_var', 'base.5.bn2.num_batches_tracked', 'base.6.conv1.weight', 'base.6.bn1.weight', 'base.6.bn1.bias', 'base.6.bn1.running_mean', 'base.6.bn1.running_var', 'base.6.bn1.num_batches_tracked', 'base.6.conv2.weight', 'base.6.bn2.weight', 'base.6.bn2.bias', 'base.6.bn2.running_mean', 'base.6.bn2.running_var', 'base.6.bn2.num_batches_tracked', 'base.6.downsample.0.weight', 'base.6.downsample.1.weight', 'base.6.downsample.1.bias', 'base.6.downsample.1.running_mean', 'base.6.downsample.1.running_var', 'base.6.downsample.1.num_batches_tracked', 'base.7.conv1.weight', 'base.7.bn1.weight', 'base.7.bn1.bias', 'base.7.bn1.running_mean', 'base.7.bn1.running_var', 'base.7.bn1.num_batches_tracked', 'base.7.conv2.weight', 'base.7.bn2.weight', 'base.7.bn2.bias', 'base.7.bn2.running_mean', 'base.7.bn2.running_var', 'base.7.bn2.num_batches_tracked', 'base.8.conv1.weight', 'base.8.bn1.weight', 'base.8.bn1.bias', 'base.8.bn1.running_mean', 'base.8.bn1.running_var', 'base.8.bn1.num_batches_tracked', 'base.8.conv2.weight', 'base.8.bn2.weight', 'base.8.bn2.bias', 'base.8.bn2.running_mean', 'base.8.bn2.running_var', 'base.8.bn2.num_batches_tracked', 'base.8.downsample.0.weight', 'base.8.downsample.1.weight', 'base.8.downsample.1.bias', 'base.8.downsample.1.running_mean', 'base.8.downsample.1.running_var', 'base.8.downsample.1.num_batches_tracked', 'base.9.conv1.weight', 'base.9.bn1.weight', 'base.9.bn1.bias', 'base.9.bn1.running_mean', 'base.9.bn1.running_var', 'base.9.bn1.num_batches_tracked', 'base.9.conv2.weight', 'base.9.bn2.weight', 'base.9.bn2.bias', 'base.9.bn2.running_mean', 'base.9.bn2.running_var', 'base.9.bn2.num_batches_tracked', 'norm.weight', 'extras.0.weight', 'extras.0.bias', 'extras.1.weight', 'extras.1.bias', 'extras.2.weight', 'extras.2.bias', 'extras.3.weight', 'extras.3.bias', 'extras.4.weight', 'extras.4.bias', 'extras.5.weight', 'extras.5.bias', 'extras.6.weight', 'extras.6.bias', 'extras.7.weight', 'extras.7.bias', 'loc.0.weight', 'loc.0.bias', 'loc.1.weight', 'loc.1.bias', 'loc.2.weight', 'loc.2.bias', 'loc.3.weight', 'loc.3.bias', 'loc.4.weight', 'loc.4.bias', 'loc.5.weight', 'loc.5.bias', 'conf.0.weight', 'conf.0.bias', 'conf.1.weight', 'conf.1.bias', 'conf.2.weight', 'conf.2.bias', 'conf.3.weight', 'conf.3.bias', 'conf.4.weight', 'conf.4.bias', 'conf.5.weight', 'conf.5.bias'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare ResNet18 compressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2pretrained_imagenet = \"/workspace/raid/data/jgusak/for_yulia/resnet18_cp3_compressed_loss1.260267.pth\"\n",
    "\n",
    "cm = torch.load(path2pretrained_imagenet).module\n",
    "dict(cm.named_children()).keys()\n",
    "\n",
    "checkpoint = copy.deepcopy(cm.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['conv1', 'bn1', 'relu', 'maxpool', 'layer1', 'layer2', 'layer3', 'layer4', 'avgpool', 'fc'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(cm.named_children()).keys()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "save_folder = '/workspace/raid/data/jgusak/ssds.pytorch/'\n",
    "torch.save(checkpoint, save_folder + 'resnet18_imagenet_cp3_compressed_ckpt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name of the weights which exists in other model\n",
    "change_dict = {\n",
    "        'bn1.running_mean':'base.1.running_mean',\n",
    "        'bn1.running_var':'base.1.running_var',\n",
    "        'bn1.bias':'base.1.bias',\n",
    "        'bn1.weight':'base.1.weight',\n",
    "        }\n",
    "\n",
    "for k, v in list(checkpoint.items()):\n",
    "    for _k, _v in list(change_dict.items()):\n",
    "        if _k == k:\n",
    "            new_key = k.replace(_k, _v)\n",
    "            checkpoint[new_key] = checkpoint.pop(k)\n",
    "            \n",
    "            \n",
    "change_dict = {'layer1.{:d}.'.format(i):'base.{:d}.'.format(i+4) for i in range(20)}\n",
    "change_dict.update({'layer2.{:d}.'.format(i):'base.{:d}.'.format(i+6) for i in range(20)})\n",
    "change_dict.update({'layer3.{:d}.'.format(i):'base.{:d}.'.format(i+8) for i in range(30)})\n",
    "\n",
    "for k, v in list(checkpoint.items()):\n",
    "    for _k, _v in list(change_dict.items()):\n",
    "        if _k in k:\n",
    "            new_key = k.replace(_k, _v)\n",
    "            checkpoint[new_key] = checkpoint.pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./experiments/cfgs/ssd_resnet18_train_voc.yml\n",
      "===> Building model\n",
      "==>Feature map size:\n",
      "[(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/home/jgusak/ssds.pytorch/lib/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n"
     ]
    }
   ],
   "source": [
    "config_file =  './experiments/cfgs/ssd_resnet18_train_voc.yml'\n",
    "cfg_from_file(config_file)\n",
    "\n",
    "print(config_file)\n",
    "\n",
    "\n",
    "# Build model\n",
    "print('===> Building model')\n",
    "model, priorbox = create_model(cfg.MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.base[0] = copy.deepcopy(cm.conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dict = model.state_dict()\n",
    "pretrained_dict = {k:v for k,v in checkpoint.items() if k in model_dict.keys()}\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading data\n"
     ]
    }
   ],
   "source": [
    " # Load data\n",
    "print('===> Loading data')\n",
    "train_loader = load_data(cfg.DATASET, 'train') if 'train' in cfg.PHASE else None\n",
    "eval_loader = load_data(cfg.DATASET, 'eval') if 'eval' in cfg.PHASE else None\n",
    "test_loader = load_data(cfg.DATASET, 'test') if 'test' in cfg.PHASE else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    priors = Variable(priorbox.forward())\n",
    "    detector = Detect(cfg.POST_PROCESS, priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilize GPUs for computation\n",
      "Number of GPU available 8\n"
     ]
    }
   ],
   "source": [
    "# Utilize GPUs for computation\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('Utilize GPUs for computation')\n",
    "    print('Number of GPU available', torch.cuda.device_count())\n",
    "    model.cuda()\n",
    "    priors.cuda()\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('', 'ssd_resnet_18_voc')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = cfg.EXP_DIR\n",
    "checkpoint = cfg.RESUME_CHECKPOINT\n",
    "checkpoint_prefix = cfg.CHECKPOINTS_PREFIX\n",
    "\n",
    "checkpoint, checkpoint_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, data_loader, detector, output_dir, use_gpu):\n",
    "        model.eval()\n",
    "\n",
    "        dataset = data_loader.dataset\n",
    "        num_images = len(dataset)\n",
    "        num_classes = detector.num_classes\n",
    "        all_boxes = [[[] for _ in range(num_images)] for _ in range(num_classes)]\n",
    "        empty_array = np.transpose(np.array([[],[],[],[],[]]),(1,0))\n",
    "\n",
    "        _t = Timer()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in iter(range((num_images))):\n",
    "                img = dataset.pull_image(i)\n",
    "                scale = [img.shape[1], img.shape[0], img.shape[1], img.shape[0]]\n",
    "                if use_gpu:\n",
    "                    images = Variable(dataset.preproc(img)[0].unsqueeze(0).cuda())\n",
    "                else:\n",
    "                    images = Variable(dataset.preproc(img)[0].unsqueeze(0))\n",
    "                _t.tic()\n",
    "                # forward\n",
    "                out = model(images, phase='eval')\n",
    "\n",
    "                # detect\n",
    "                detections = detector.forward(out)\n",
    "\n",
    "                time = _t.toc()\n",
    "\n",
    "                # TODO: make it smart:\n",
    "                for j in range(1, num_classes):\n",
    "                    cls_dets = list()\n",
    "                    for det in detections[0][j]:\n",
    "                        if det[0] > 0:\n",
    "                            d = det.cpu().numpy()\n",
    "                            score, box = d[0], d[1:]\n",
    "                            box *= scale\n",
    "                            box = np.append(box, score)\n",
    "                            cls_dets.append(box)\n",
    "                    if len(cls_dets) == 0:\n",
    "                        cls_dets = empty_array\n",
    "                    all_boxes[j][i] = np.array(cls_dets)\n",
    "\n",
    "                # log per iter\n",
    "                log = '\\r==>Test: || {iters:d}/{epoch_size:d} in {time:.3f}s [{prograss}]\\r'.format(\n",
    "                        prograss='#'*int(round(10*i/num_images)) + '-'*int(round(10*(1-i/num_images))), iters=i, epoch_size=num_images,\n",
    "                        time=time)\n",
    "                sys.stdout.write(log)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        # write result to pkl\n",
    "        with open(os.path.join(output_dir, 'detections.pkl'), 'wb') as f:\n",
    "            pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        # currently the COCO dataset do not return the mean ap or ap 0.5:0.95 values\n",
    "        print('Evaluating detections')\n",
    "        data_loader.dataset.evaluate_detections(all_boxes, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>Test: || 39/4952 in 1.002s [----------]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-16bfcbcc2235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_compressed'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-c0bef47f5956>\u001b[0m in \u001b[0;36mtest_epoch\u001b[0;34m(model, data_loader, detector, output_dir, use_gpu)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;31m# detect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0mdetections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/home/jgusak/ssds.pytorch/lib/layers/functions/detection.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, predictions)\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mboxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoded_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;31m# idx of highest scoring and non-overlapping boxes per class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                     torch.cat((scores[ids[:count]].unsqueeze(1),\n",
      "\u001b[0;32m/workspace/home/jgusak/ssds.pytorch/lib/utils/box_utils.py\u001b[0m in \u001b[0;36mnms\u001b[0;34m(boxes, scores, overlap, top_k)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0myy2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;31m# store element-wise max with next highest score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m         \u001b[0mxx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m         \u001b[0myy1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myy1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mxx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_epoch(model, test_loader, detector, output_dir+'_compressed', use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
