{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,7\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./experiments/cfgs/ssd_lite_mobilenetv2_train_voc.yml\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from lib.utils.config_parse import cfg_from_file\n",
    "from lib.ssds_train import test_model, train_model\n",
    "\n",
    "from lib.dataset.dataset_factory import load_data\n",
    "from lib.utils.config_parse import cfg\n",
    "from lib.modeling.model_builder import create_model\n",
    "\n",
    "from lib.layers import Detect\n",
    "from lib.utils.timer import Timer\n",
    "\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "config_file =  './experiments/cfgs/ssd_lite_mobilenetv2_train_voc.yml'\n",
    "cfg_from_file(config_file)\n",
    "\n",
    "print(config_file)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Loading data\n"
     ]
    }
   ],
   "source": [
    " # Load data\n",
    "print('===> Loading data')\n",
    "train_loader = load_data(cfg.DATASET, 'train') if 'train' in cfg.PHASE else None\n",
    "eval_loader = load_data(cfg.DATASET, 'eval') if 'eval' in cfg.PHASE else None\n",
    "test_loader = load_data(cfg.DATASET, 'test') if 'test' in cfg.PHASE else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> Building model\n",
      "==>Feature map size:\n",
      "[(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/home/jgusak/ssds.pytorch/lib/layers/modules/l2norm.py:17: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(self.weight,self.gamma)\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "print('===> Building model')\n",
    "model, priorbox = create_model(cfg.MODEL)\n",
    "with torch.no_grad():\n",
    "    priors = Variable(priorbox.forward())\n",
    "    detector = Detect(cfg.POST_PROCESS, priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained weights\n",
    "\n",
    "state_dict_path = \"/workspace/raid/data/jgusak/ssds.pytorch/mobilenet_v2_ssd_lite_voc_73.2.pth\"\n",
    "state_dict = torch.load(state_dict_path)\n",
    "\n",
    "\n",
    "model_dict = model.state_dict()\n",
    "pretrained_dict = {k: v for k, v in state_dict.items() \n",
    "                   if k in model_dict}\n",
    "\n",
    "model_dict.update(pretrained_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "# model.load_state_dict(torch.load(state_dict_path))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model_dict = model.state_dict()\n",
    "\n",
    "for k,v in state_dict.items():\n",
    "    if v.shape != model_dict[k].shape:\n",
    "        print(k, v.shape, model_dict[k].shape)\n",
    "    else:\n",
    "        print('yp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilize GPUs for computation\n",
      "Number of GPU available 2\n"
     ]
    }
   ],
   "source": [
    "# Utilize GPUs for computation\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print('Utilize GPUs for computation')\n",
    "    print('Number of GPU available', torch.cuda.device_count())\n",
    "    model.cuda()\n",
    "    priors.cuda()\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/workspace/raid/data/jgusak/ssds.pytorch/mobilenet_v2_ssd_lite_voc_73.2.pth',\n",
       " 'ssd_lite_mobilenet_v2_voc')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = cfg.EXP_DIR\n",
    "checkpoint = cfg.RESUME_CHECKPOINT\n",
    "checkpoint_prefix = cfg.CHECKPOINTS_PREFIX\n",
    "\n",
    "checkpoint, checkpoint_prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, data_loader, detector, output_dir, use_gpu):\n",
    "        model.eval()\n",
    "\n",
    "        dataset = data_loader.dataset\n",
    "        num_images = len(dataset)\n",
    "        num_classes = detector.num_classes\n",
    "        all_boxes = [[[] for _ in range(num_images)] for _ in range(num_classes)]\n",
    "        empty_array = np.transpose(np.array([[],[],[],[],[]]),(1,0))\n",
    "\n",
    "        _t = Timer()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in iter(range((num_images))):\n",
    "                img = dataset.pull_image(i)\n",
    "                scale = [img.shape[1], img.shape[0], img.shape[1], img.shape[0]]\n",
    "                if use_gpu:\n",
    "                    images = Variable(dataset.preproc(img)[0].unsqueeze(0).cuda())\n",
    "                else:\n",
    "                    images = Variable(dataset.preproc(img)[0].unsqueeze(0))\n",
    "                _t.tic()\n",
    "                # forward\n",
    "                out = model(images, phase='eval')\n",
    "\n",
    "                # detect\n",
    "                detections = detector.forward(out)\n",
    "\n",
    "                time = _t.toc()\n",
    "\n",
    "                # TODO: make it smart:\n",
    "                for j in range(1, num_classes):\n",
    "                    cls_dets = list()\n",
    "                    for det in detections[0][j]:\n",
    "                        if det[0] > 0:\n",
    "                            d = det.cpu().numpy()\n",
    "                            score, box = d[0], d[1:]\n",
    "                            box *= scale\n",
    "                            box = np.append(box, score)\n",
    "                            cls_dets.append(box)\n",
    "                    if len(cls_dets) == 0:\n",
    "                        cls_dets = empty_array\n",
    "                    all_boxes[j][i] = np.array(cls_dets)\n",
    "\n",
    "                # log per iter\n",
    "                log = '\\r==>Test: || {iters:d}/{epoch_size:d} in {time:.3f}s [{prograss}]\\r'.format(\n",
    "                        prograss='#'*int(round(10*i/num_images)) + '-'*int(round(10*(1-i/num_images))), iters=i, epoch_size=num_images,\n",
    "                        time=time)\n",
    "                sys.stdout.write(log)\n",
    "                sys.stdout.flush()\n",
    "\n",
    "        # write result to pkl\n",
    "        with open(os.path.join(output_dir, 'detections.pkl'), 'wb') as f:\n",
    "            pickle.dump(all_boxes, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        # currently the COCO dataset do not return the mean ap or ap 0.5:0.95 values\n",
    "        print('Evaluating detections')\n",
    "        data_loader.dataset.evaluate_detections(all_boxes, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f74e72aa7b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating detections in 0.098s [##########]\n",
      "Writing aeroplane VOC results file\n",
      "Writing bicycle VOC results file\n",
      "Writing bird VOC results file\n",
      "Writing boat VOC results file\n",
      "Writing bottle VOC results file\n",
      "Writing bus VOC results file\n",
      "Writing car VOC results file\n",
      "Writing cat VOC results file\n",
      "Writing chair VOC results file\n",
      "Writing cow VOC results file\n",
      "Writing diningtable VOC results file\n",
      "Writing dog VOC results file\n",
      "Writing horse VOC results file\n",
      "Writing motorbike VOC results file\n",
      "Writing person VOC results file\n",
      "Writing pottedplant VOC results file\n",
      "Writing sheep VOC results file\n",
      "Writing sofa VOC results file\n",
      "Writing train VOC results file\n",
      "Writing tvmonitor VOC results file\n",
      "VOC07 metric? Yes\n",
      "AP for aeroplane = 0.7730\n",
      "AP for bicycle = 0.8090\n",
      "AP for bird = 0.6643\n",
      "AP for boat = 0.6301\n",
      "AP for bottle = 0.4154\n",
      "AP for bus = 0.8474\n",
      "AP for car = 0.8182\n",
      "AP for cat = 0.8315\n",
      "AP for chair = 0.5575\n",
      "AP for cow = 0.7310\n",
      "AP for diningtable = 0.7363\n",
      "AP for dog = 0.7971\n",
      "AP for horse = 0.8436\n",
      "AP for motorbike = 0.8257\n",
      "AP for person = 0.7629\n",
      "AP for pottedplant = 0.4806\n",
      "AP for sheep = 0.7158\n",
      "AP for sofa = 0.7828\n",
      "AP for train = 0.8302\n",
      "AP for tvmonitor = 0.7219\n",
      "Mean AP = 0.7287\n",
      "~~~~~~~~\n",
      "Results:\n",
      "0.773\n",
      "0.809\n",
      "0.664\n",
      "0.630\n",
      "0.415\n",
      "0.847\n",
      "0.818\n",
      "0.831\n",
      "0.558\n",
      "0.731\n",
      "0.736\n",
      "0.797\n",
      "0.844\n",
      "0.826\n",
      "0.763\n",
      "0.481\n",
      "0.716\n",
      "0.783\n",
      "0.830\n",
      "0.722\n",
      "0.729\n",
      "~~~~~~~~\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Results computed with the **unofficial** Python eval code.\n",
      "Results should be very close to the official MATLAB eval code.\n",
      "Recompute with `./tools/reval.py --matlab ...` for your paper.\n",
      "-- Thanks, The Management\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "test_epoch(model, test_loader, detector, output_dir, use_gpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
